import os
import json
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
from bias_checker import assessing_bias

load_dotenv()

OPEN_AI_API_KEY = os.getenv("OPENAI_API_KEY")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")

model = init_chat_model("gpt-4o-mini", model_provider="openai", api_key=OPEN_AI_API_KEY)

def returnArguments(argument: str, model):
    ##Prompts
    system_template = "You are an expert in  {specialization}" \
    "Another expert is arguing their point of view of a topic and you are tasked to judge their argument " \
    "based on your experience and specialization. After judging, provide your own argument against them in 200-300 words. " 
    
    ##Individual templates
    templateECON = ChatPromptTemplate.from_messages(
        [("system", system_template), ("user", "This is their argument: {text}")]
    )

    templateENV = ChatPromptTemplate.from_messages(
        [("system", system_template), ("user", "This is their argument: {text}")]
    )

    templateSOC = ChatPromptTemplate.from_messages(
        [("system", system_template), ("user", "This is their argument: {text}")]
    )
    ##Run templates
    promptECON = templateECON.invoke({"specialization": 
                                      "economics and issues dealing with economics,"
                                      " both globally and domestically in various specific "
                                      "countries in the world.", "text": argument})
    promptENV = templateECON.invoke({"specialization": "environmental sciences and issues.",
                                        "text": argument})
    promptSOC = templateSOC.invoke({"specialization": "sociology and human rights advocacy.",
                                    "text": argument})
    
    ##Get responses
    responseECON = model.invoke(promptECON)
    responseENV = model.invoke(promptENV)
    responseSOC = model.invoke(promptSOC)

    ##Create result json
    result = {
        "Economics": responseECON.content,
        "Environment": responseENV.content,
        "Sociology": responseSOC.content,
        "Argument": argument
    }

    # Ensure AI_Arguments.json exists
    if os.path.exists("AI_Arguments.json") and os.path.getsize("AI_Arguments.json") > 0:
        with open("AI_Arguments.json", "r") as file:
            data = json.load(file)
        data.append(result)
    else:
        data = [result]

    with open("AI_Arguments.json", "w") as file:
        json.dump(data, file, indent=4)

    assessing_bias("AI_Arguments.json", model)

    return result

def reading_json(filename: str) -> dict[str, str]:
    """
    Reads the JSON file and returns the data as a dictionary
    with original and AI 1st suggested draft argument
    """
    with open(filename, "r") as file:
        data = json.load(file)
    
    word_transcript = {}
    dif_roles = ""
    for speakers in data:
        if "Argument" in speakers:
            word_transcript["Arguments"] = speakers["Argument"]
        if "Economics" in speakers:
            dif_roles += speakers["Economics"] + ";"
        if "Environment" in speakers:
            dif_roles += speakers["Environment"] + ";"
        if "Sociology" in speakers:
            dif_roles += speakers["Sociology"] + ";"
    word_transcript["draft_prospectives"] = dif_roles
    return word_transcript

def assessing_bias(filename: str, model):
    """
    Convert system and user text into messages that can be used by langchain
    Return dict of the updated text with biases removed
    """
    given_dict = reading_json(filename)

    system_template = "You're an expert in {bias_finder}" \
    " Your job is to assess the argument recommended by another chatbot {draft_prospectives}. The other argument is based on" \
    " the triple-bottom-line framework. The triple-bottom-line framework is a theory that includes an organization's contributions" \
    " to social well-being, environmental health, and a just economy." \
    " You will compare the given user message {user} to the proposed argument the previous chatbot provided and assess it for ethical biases and concerns." \
    " Then, you should return a more ethically bound, less discriminatory response to further reinforce the rubrics while accounting for biases. Word limit: 50"

    prompt_template = ChatPromptTemplate.from_messages([
        {"role": "system", "content": system_template},
        {"role": "user", "content": given_dict["Arguments"]},  # User input for comparison
        {"role": "system", "content": given_dict["draft_prospectives"]}  # Old chatbot response
    ])

    prompt = prompt_template.invoke({
        "bias_finder": "An expert in detecting ethical biases, ensuring fairness, and refining arguments for inclusivity, social well-being, environmental health, and economic justice.",
        "draft_prospectives": "An argument generated by a previous chatbot for assessment and ethical refinement.",
        "user": given_dict["Arguments"]
    })
    response = model.invoke(prompt)
        
    return_json("ai_response.json", response.content)

def return_json(filename: str, new_argument: str):
    """
    Updating the JSON file with the suggestions
    """
    if os.path.exists(filename) and os.path.getsize(filename) > 0:
        with open(filename, "r") as f:
            data = json.load(f)  # Parse JSON into a dictionary
    else:
        data = [{"filtered_response": []}]

    data[0]["filtered_response"].append({"response": new_argument})

    with open(filename, "w") as f:
        json.dump(data, f, indent=4)

def return_argument_clean():
    """Print the outputs"""
    if os.path.exists("ai_response.json") and os.path.getsize("ai_response.json") > 0:
        with open("ai_response.json", "r") as file:
            data = json.load(file)
            for i in data:
                print(i)
    else:
        print("No data found")

if __name__ == "__main__":
    argument = "College tuition should be free for all students. " \
    "In doing this, the workforce will be more educated and skilled. " \
    "In combination with this, competition is driven increasing the productivity of students."
    argument2 = ""

    with open("conversations.json", "r") as file:
        data = json.load(file)
        arguemtent2 = data[0]

    result = returnArguments(argument2, model)
    return_argument_clean()
    print(json.dumps(result, indent=4))